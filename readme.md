# Hello!

This is (probably) where I'll stick writeups on more theoretical topics, for future reference (mainly to remind myself of intuitions I sometimes forget). Currently has stuff on:

- Bayes' Theorem
- Entropy, Cross-Entropy, and KL Divergence (and I guess mutual information?)
- Constrained Optimization (Lagrangian; KKT conditions)
- Boosting meta-algorithms, with gradient boosting as a more concrete example
- The Boltzmann Distribution, and what assumptions could be changed to lead to the Bose-Einstein or Fermi-Dirac distributions.

(The PDF has a clickable table of contents that it seems Github isn't able to render on-site. It does work when downloaded though!)