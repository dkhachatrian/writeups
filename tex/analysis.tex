\documentclass[../main/main.tex]{subfiles}
\begin{document}

\chapter{Analysis.}\label{chapter:analysis}

(Currently in its infancy \textemdash{} we're starting
with discussions about ``simple'' calculus at the moment.)

\section{Directional derivatives and the gradient.}

Why does the gradient of a function \(f\), \(\grad{f}\),
point to the ``direction of steepest ascent'' for functions?
To answer that, we need to remember 
about directional derivatives.

\subsection{Partial derivatives.}

As a reminder, we define a 
\textbf{partial derivative}\index{partial derivative}
as a limit along one variable, akin to the derivative
of a one-variable function.

\[\begin{split}
  \pdv{}{x_i}f(x_1, x_2, \cdots, x_i, \cdots, x_n) \definedas \lim_{h \rightarrow 0} \frac{f(x_1, x_2, \cdots, x_i + h, \cdots, x_n) - f(x_1, x_2, \cdots, x_i, \cdots, x_n)}{h}, 
  \\
  h \in \domain{R}, Dom(f) \in \domain{R}^n
\end{split}\]

Let's remember that for a limit to exist at a point, it
must approach the same value regardless of the ``side''
from which the point is approached. For limits that approach
a point \(p\) in \domain{R}, 
there are only two ``sides'' in \domain{R} from
which the point can be approached: from values smaller
than \(p\) and from values larger than \(p\).

\[p \in \domain{R}, \lim_{x \rightarrow p}g(x) = c 
\quad \longleftrightarrow \quad
\lim_{x \rightarrow p^-}g(x) = \lim_{x \rightarrow p^+}g(x) = c\]

\subsection{Directional derivatives.}

Anyway, this is great for when we happen to want to 
approach our point \(p\) 
along one of the ``predefined'' axes \(x_1, x_2, \cdots, x_n\).
But what if we want to approach our point along a
\emph{different} line? For example, let's stick to two
dimensions (so \(f: \domain{R}^2 \to \domain{R}\)) and say we want to approach \(p\) along the line
\(x_2 = bx_1, \ b \in \domain{R}\). We could calculate this
\textbf{directional derivative} via the following expression:

\[\lim_{h \to 0} \frac{f(x_1 + h, x_2 + bh) - f(x_1,x_2)}{h} \]

More cleanly, we can associate the line of approach with a vector
\(\vec{v} = (1,b)\) and use vector notation:

\[\lim_{h \to 0} \frac{f(\vec{x} + h\vec{v}) - f(\vec{x})}{h} \]

where in this case \(\vec{x} \in \domain{R}^2\).\par
But wait! Aren't there an infinite number of points on our line
and so an infinite number of potential \(\vec{v}\) to choose
from? Indeed there are, and for the limit above to exist
they should all yield the same result (i.e., 
we should get the same answer whether we start
from the ``left'' or the ``right'' of \(h = 0\)). To disambiguate
a bit, we'll constrain our line-of-approach vector to have
a norm of 1, i.e., 
we'll have \(\vec{u}\) be a \emph{unit vector}.
This allows us to finally properly define the 
\textbf{directional derivative} operator \(D_{\vec{u}}\)
as

\[D_{\vec{u}} = \lim_{h \to 0} \frac{f(\vec{x} + h\vec{u}) - f(\vec{x})}{h} \]

From this definition, we can see that our definition of a
partial derivative \(\pdv{f}{x_i}\),
our approach along a ``predefined'' axis, 
is simply a directional
derivative along the standard basis vector \(\vec{e}_i\).\par

So our directional derivative definition is a valid 
\emph{extension}
of the definition of a partial derivative. Neat. 
But can we actually calculate it? Finding limits along an
arbitrary axis seems like a huge pain. (And in fact,
it is.) But wait, we observed that
a partial derivative along a natural axis \(x_i\)
is the directional derivative 
along the natural basis vector \(e_i\):

\[ D_{e_i}f = \pdv{f}{x_i} \]

And normally in linear algebra, we can define vectors
in terms of a linear combination of 
a set of basis vectors (say the natural basis
vectors \(\{\vec{e}_i\}\)):

\[\exists \vec{\lambda} = \left(\lambda_1, \lambda_2, \cdots, \lambda_n\right) \suchthat \vec{v} = \sum_i \lambda_i \vec{e}_i \]

Can we define our directional derivative along a unit vector
\(\vec{u}\) as a linear combination of 
the directional derivative along
the natural basis vectors \(e_i\)? In fact, we can!
And with both \(\vec{u}\) and \(e_i\) having unit norm, 
it's just as simple
as weighting the partial derivative of each \(\pdv{f}{x_i}\)
by \(\lambda_i \setequalto \innerprod{\vec{u}}{\vec{e}_i} = u_i\):

\[\begin{split}
  D_{\vec{u}}f &= \sum_i \lambda_i D_{\vec{e_i}}f \\
      &= \sum_i \innerprod{\vec{u}}{\vec{e}_i} \pdv{f}{x_i} \\
      &= \sum_i u_i \pdv{f}{x_i} \\
      &= \innerprod{\vec{u}}{\grad{f}}
\end{split}
\]

where 
\(\grad{f} = \left(\pdv{f}{x_1}, \pdv{f}{x_2}, \cdots, \pdv{f}{x_n}\right)\)
is the \textbf{gradient operator} and 
\(\innerprod{\cdot}{\cdot}\) denotes the inner product
on our domain \(\domain{R}^n\), i.e.,
the \emph{dot product}.\footnote
{
A rigorous proof would involve defining a single-input function
\(g(z)\) which moves along the unit vector \(u\) and
noting that \(g'(0)\) equals both the definition of the
directional derivative and the result we achieved by our
linear-algebra reasoning.
}\par

Note that this expression for the directional derivative
explains why the gradient of a function at that point is
often intuitively explained as 
``the direction of steepest ascent''. Specifically,
if we wished to maximize \(D_{\vec{u}}\), we'd have

\[
  \argmax_{\vec{u}}(D_{\vec{u}}(f)) 
  = \argmax_{\vec{u}}\innerprod{\vec{u}}{\grad{f}}
\]

and by the properties of the dot product,
\(\innerprod{\vec{u}}{\grad{f}} = 
\norm{\vec{u}}\norm{\grad{f}}\cos(\theta)\) where
\(\theta\) is the angle between the two vectors.
We have constrained \(\norm{u} = 1\) and so we
maximize the expression by having \(cos(\theta) = 1\), 
i.e. \(\theta = \cos^{-1}(1) = 0\).
So there is \emph{no} angle between \(\vec{u}\)
and \(\grad{f}\), so \(\vec{u}\) points in the direction
of \(\grad{f}\). In math-speak,

\[
  \argmax_{\vec{u}}(D_{\vec{u}}(f)) 
  = \frac{\grad{f}}{\norm{\grad{f}}}
\]

and by substituting the value for \(\vec{u}\)
and noting that \(\cos(\theta) = 1\), we have

\[
  \max_{\vec{u}}(D_{\vec{u}}(f)) 
  = \norm{\grad{f}}
\]

To find the direction of steepest \emph{descent} at 
some point \(p\),
we instead find the vector such that \(\cos(\theta) = -1\),
i.e. \(\theta = \pi\), meaning the vectors are antiparallel.
Then we have

\[
  \argmin_{\vec{u}}(D_{\vec{u}}(f)) 
  = \frac{-\grad{f}}{\norm{\grad{f}}}
\]

and now

\[
  \min_{\vec{u}}(D_{\vec{u}}(f)) 
  = -\norm{\grad{f}}
\]

which, when considering partial derivatives as ``slopes''
along each axis (like how we often think of 1-D derivatives),
should make sense.
A differential step ``up'' the \(x_i\) axis 
and a differential step ``down'' the \(x_i\) axis
would have the same magnitude \(\pdv{f}{x_i}\) and so differ
only by a negative sign.
This holds for all \(x_i\), so it ought to hold
for the gradient as well.

% To find the direction of steepest \emph{descent} at 
% some point \(p\),
% we note that if the directional derivative exists
% along the \(\grad{f}\) axis, then 
% a step ``up'' from \(p\) along the \(\grad{f}\) axis 
% and a step ``down'' from \(p\) along the \(\grad{f}\) axis 
% will have the same magnitude \(\norm{\grad{f}}\)
% for a differential step \(dp\).
% And we previously found that \(\norm{\grad{f}}\)
% is the largest magnitude we can get for a directional derivative
% and is attained with the unit vector along the \(\grad{f}\)
% axis.
% So then the direction of steepest descent is ``down'' the
% axis, i.e., in the direction of \(-\grad{f}\).

% \subsection{Beyond lines: conservative vector fields.}

% This is great if we're only interested getting to our 
% destinations along specific lines, but things may break
% if we \sout{read} move between the lines and 
% go along different \emph{curves}. 
% For example, what if we did some silly ``rotational derivative''
% toward a point \(p\), i.e.,

% \[\vec{u}(r) = \left(r\cos(\frac{\theta}{r}), r\sin(\frac{\theta}{r})\right) \implies \lim_{r \to 0}\frac{f(\vec{p} + \vec{u}(r)) - f(\vec{p})}{r} = R_{\theta}f(p) = \ ? \]

% I mean, it feels like \(R_{\theta}f(p)\) \emph{should} have
% a value, since it's approaching \(p\)
% and we can define a directional derivative for any
% arbitary angle of approach \(u\) via \(D_{u}f\). 
% But which \(u\) should correspond to \(D_{u}f = R_{\theta}f\)?
% How would one choose the \(u\)?\par

% Well, the answer is ``''


% \subsection{Directional derivatives in the complex plane.}

% Now let's consider a function \(f: \domain{C} \to \domain{C}\) which takes in a \emph{complex} input \(z \in \domain{C}\)
% and returns a complex output \(f(z)\).
% \(\domain{C}\) is quite similar to \(\domain{R}^2\) in some
% ways, with real and imaginary axes. So we can break down
% our input \(z = x + iy\) in terms of its real and imaginary
% components, and also describe the output components
% in terms of these components
% \(f(z) = f(x + iy) = u(x,y) + v(x,y)i\).\par

% Now, if we want a derivative to exist in the \emph{complex}
% plane, we'd the limit of a directional derivative with
% unit vector \(\vec{c} \in \domain{C}\)

% \[ D_{\vec{c}}f(z) = \lim_{h \to 0} \frac{f(z + h\vec{c}) - f(z)}{h} \]

% to exist and be equivalent for \emph{all} unit vectors 
% \(\vec{c} \in \domain{C}\).
% Otherwise the limit as \(h \to 0\) doesn't make sense.
% This is analogous to how, for a regular 1-D real-valued
% derivative, we'd consider it to exist only if the limit
% as we approached it from \emph{every possible ``angle'' of
% approach} agreed with one another. It's just that in
% the 1-D case, there's only two ``angles'' from which
% we can approach a point: 
% from its ``left'' and from its ``right''.\footnote{
%   Recall the mathematical formulation of the above:
%   \[p \in \domain{R}, \lim_{x \rightarrow p}g(x) = c 
% \quad \longleftrightarrow \quad
% \lim_{x \rightarrow p^-}g(x) = \lim_{x \rightarrow p^+}g(x) = c\]

% \(p^-\) and \(p^+\) are the two angles, ``left'' and ``right'',
% from which we can approach the point.
% }\par

% OK, then how could we make \emph{every} possible angle of
% approach agree with one another? There's an (uncountably)
% infinite number of such approaches! Well, we can
% rely on our previous realization: if we have directional
% derivatives along a set of basis vectors \(b_1\) and \(b_2\)
% for the domain in
% question, we can describe any other directional derivative
% as a linear combination of the ones we've computed.
% Once again, we'd choose the natural basis vectors
% \(e_1\) and \(e_2\), where this time
% \(e_1 = \hat{x}\) (for the real axis)
% and \(e_2 = \hat{iy} = i\hat{y}\) (for the imaginary axis).
% Then once again, the weighting scheme for a directional
% derivative defined by the unit vector \(\vec{c}\)
% is just
% \(\lambda_i = \innerprod{\vec{c}}{\vec{e_i}}\).\par
% % Once again, limiting ourselves to unit vectors \(\hat{c}\),
% % and assuming we choose natural basis vectors (of unit norm)
% % \(e_1\) and \(e_2\), the scalar value we'd have for each
% The complex plane is isomorphic to \(\domain{R}^2\) and
% only has two basis vectors along which we need to evaluate
% \textemdash{} let's choose the real and imaginary axes
% \(x\) and \(iy\). Say they were equal at some point \(p\), i.e.,

% \[\pdv{f}{x}(p) = \pdv{f}{iy}(p) = g(p)\]

% Then, since we would describe every other derivative
% as a linear combination of \(\pdv{f}{x}(p)\) and
% \(\pdv{f}{iy}(p)\)



\subsection*{References.}

\href{http://tutorial.math.lamar.edu/Classes/CalcIII/DirectionalDeriv.aspx}{Paul's notes} 
seem to always be there for all things calculus.


\end{document}